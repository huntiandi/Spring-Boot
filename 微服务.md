 

# 微服务

## 技术栈

1. 服务集群
2. 注册中心（拉取注册服务信息）
3. 配置中心（拉去配置中心）
4. 服务网关（请求路由，负载均衡）
5. 分布式缓存
6. 分布式搜索
7. 数据库集群
8. 消息队列
9. 分布式日志服务
10. 系统监控链路追踪
11. Jenkins自动化部署
12. docker打包镜像

<img src="C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20240326102320821.png" alt="image-20240326102320821" style="zoom: 67%;" />

## 微服务治理

### 微服务

#### 基本概念

- 区分分布式：

  - 微服务是将服务拆分成很小的独立服务，服务之间可以通过RPC进行通信；分布式是系统的部署方式

  例如将服务部署到不同多个机器，集群，主从都是这个意思；分布式是部署方式而微服务是对服务的拆分

- 单体架构：所有功能集中在一个项目中开发，打一个包部署；
  - 架构简单，部署成本低
  - 耦合性高
- 分布式架构：根据业务模块拆分，每个业务是一个独立模块，是一个服务
  - 减低耦合，有利于服务拓展
  - 服务拆分粒度，服务集群维护，服务远程调用，服务健康状态
- 微服务：良好架构的分布式架构方案
  - 拆分粒度更小，耦合度更低
  - 架构更加复杂，运维更加复杂
  - spring Cloud+Feign；Spring CloudAlibaba+Dubbo
- SpringCloud：是目前国内使用最广泛的微服务框架。官网地址：https://spring.io/projects/spring-cloud。

#### 服务拆分

- 不同微服务，不要重复开发相同业务
- 微服务数据独立，不要访问其它微服务的数据库
- 微服务可以将自己的业务暴露为接口，供其它微服务调用（可以使用RestTemplate来进行远程调用）

### eureka注册中心

#### 基本概念

- 服务启动后会自动注册到eureka的注册中心；服务注册后每隔三十秒会向eurake做心跳检测
- 服务请求时会向eureka获取提供者的信息，基于服务列表根据负载均衡选取一个发起请求

#### 搭建服务

```xml
<dependency>
    <groupId>org.springframework.cloud</groupId>
	<!--eureka服务端依赖-->
    <artifactId>spring-cloud-starter-netflix-eureka-server</artifactId>
    <!--eureka客户端依赖，注册-->
    <artifactId>spring-cloud-starter-netflix-eureka-client</artifactId>
</dependency>
```

1. 创建一个独立的springboot服务，引入依赖

```properties
server:
  port: 10086 # 服务端口
spring:
  application:
    name: eurekaserver # eureka的服务名称
eureka:
  client:
    service-url:  # eureka的地址信息
      defaultZone: http://127.0.0.1:10086/eureka
```

1. 配置文件中配置信息，eurake也要把自己注册到eurake上面，方便通信
2. 给RestTemplate加上@LoadBalanced注解负载均衡去请求

### Ribbon负载均衡

#### 基本概念

- SpringCloud底层其实是利用了一个名为Ribbon的组件，来实现负载均衡功能的。
- LoadBalancerIntercepor拦截器拦截请求获取uri路径的主机名；根据id去eureka中获取服务列表
- `getServer`方法来做负载均衡；IRule利用内置负载均衡规则，从列表中选择一个（轮播或随机等等）

#### 修改规则

- 通过定义IRule实现可以修改负载均衡规则，有两种方式：

  1. 代码方式：在order-service中的OrderApplication类中，定义一个新的IRule：
  2. 这种方式会影响该服务的所有请求

  ```java
  @Bean
  public IRule randomRule(){
      return new RandomRule();
  }
  ```

  1. 配置文件方式：在order-service的application.yml文件中，添加新的配置也可以修改规则：
  2. 给某个微服务配置负载均衡规则，这里是userservice服务

  ```yaml
  userservice: 
    ribbon:
      NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule # 负载均衡规则 
  ```


#### 饿加载

- ribbon默认是懒加载，也就是说只有使用的时候才创建LoadBalanceClient，请求时间会很长。

- 而饥饿加载则会在项目启动时创建，降低第一次访问的耗时，通过下面配置开启饥饿加载：

  ```yaml
  ribbon:
    eager-load:
      enabled: true
      clients: # 指定饥饿加载的服务名称，可以是多个
      	- userservice
  ```


### nacos注册中心

#### 基本概念

- https://nacos.io 官网地址，下载适合的nacos解压即可
- 在bin文件中startup.cmd -m standalone启动nacos，即可打开用户名和密码都是nacos

#### 注册与发现

- 在cloud-demo父工程的pom文件引入SpringCloudAlibaba的依赖：

  ```xml
  <dependency>
      <groupId>com.alibaba.cloud</groupId>
      <artifactId>spring-cloud-alibaba-dependencies</artifactId>
      <version>2.2.6.RELEASE</version>
      <type>pom</type>
      <scope>import</scope>
  </dependency>
  ```

  然后在user-service和order-service中的pom文件中引入nacos-discovery依赖：

  ```xml
  <dependency>
      <groupId>com.alibaba.cloud</groupId>
      <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>
  </dependency>
  ```

- 在user-service和order-service的application.yml中添加nacos地址：

  ```yaml
  spring:
    cloud:
      nacos:
        server-addr: localhost:8848
  ```


#### 负载均衡与权重

- 通过discovery:  cluster-name: 来配置集群模式，集群配置后，服务会优先访问相同集群，若本集群全部挂掉则访问非本集群同时会发出警报；
- 但是要通过 NFLoadBalancerRuleClassName: com.alibaba.cloud.nacos.ribbon.NacosRule # 负载均衡规则 才能实现上述规则；并且nacosRule是随机访问
- 但是可以设置权重，例如将a实例权重调整为0.1(可调整范围：0-1)，则会大大降低访问几率，如果调整为0则不会访问

#### 环境隔离

- namespace来做到环境隔离，例如多人开发，或者不同的dev生产环境等
- 修改yml文件的 namespace: 492a7d5d-237b-46a1-a99a-fa8e98e4b0f9 # 命名空间，填ID  控制
- 不同空间互不可见

#### eureka与Nacos

- 都支持服务的注册与发现
- 都支持心跳检测
- nacos可以设置非临时实例来做主动询问（非临时实例挂了也不会被剔除），以达到及时更新服务状态
- nacos支持主动推送服务信息到消费者，服务列表的及时更新

### nacos配置管理

#### 统一配置管理

1. 在nacos中的配置管理中新建一个配置，注意DataId要用-不能用其他的要不然就不认识了；选择yaml格式

2. 引入nacos-config的客户端依赖：

   ```xml
   <!--nacos配置管理依赖-->
   <dependency>
       <groupId>com.alibaba.cloud</groupId>
       <artifactId>spring-cloud-starter-alibaba-nacos-config</artifactId>
   </dependency>
   ```

   2）添加bootstrap.yaml，这个yaml的优先级要大于application.yaml；因此会先加载nacos中的配置

   然后，在user-service中添加一个bootstrap.yaml文件，内容如下：

   ```yaml
   spring:
     application:
       name: userservice # 服务名称
     profiles:
       active: dev #开发环境，这里是dev 
     cloud:
       nacos:
         server-addr: localhost:8848 # Nacos地址
         config:
           file-extension: yaml # 文件后缀名
   ```

   这里会根据spring.cloud.nacos.server-addr获取nacos地址，再根据

   `${spring.application.name}-${spring.profiles.active}.${spring.cloud.nacos.config.file-extension}`作为文件id，来读取配置。因此我们命名也要注意

   3）在获取配置管理中的配置时，我们有两种获取方式@Value和@ConfigurationProperties；如果使用@Value需要在@Value的类上添加@RefreshScope来实现热更新；而如果使用的是@ConfigurationProperties会自动实现热更新

   4）在读取时，会读取两个文件一个是带环境的文件例如userservice-dev.yaml和不带环境的userserviec.yaml两个文件；而优先级是userservice-dev.yaml>userservice.yaml>本地环境的配置文件。

### Feign接口 

#### 基本概念

- 在服务的pom文件中引入feign的依赖：


```xml
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-openfeign</artifactId>
</dependency> 
```

- 在启动类添加@EnableFeignClients注解开启feign功能
- 编写feign接口，在接口上添加@FeignClient("userservice")注解来实现feign的调用，Feign就可以帮助我们发送http请求
- 方法其实和controller里面的一模一样就可以了

#### 配置&优化

- 修改日志的范围；可以针对所有服务：


```yaml
feign:  
  client:
    config: 
      default: # 这里用default就是全局配置，如果是写服务名称，则是针对某个微服务的配置
        loggerLevel: FULL #  日志级别 一般使用none或者basic
```

- 提高Feign的性能主要手段就是使用**连接池**代替默认的URLConnection

1）引入依赖

在order-service的pom文件中引入Apache的HttpClient依赖：

```xml
<!--httpClient的依赖 -->
<dependency>
    <groupId>io.github.openfeign</groupId>
    <artifactId>feign-httpclient</artifactId>
</dependency>
```



2）配置连接池

在order-service的application.yml中添加配置：

```yaml
feign:
  client:
    config:
      default: # default全局的配置
        loggerLevel: BASIC # 日志级别，BASIC就是基本的请求和响应信息
  httpclient:
    enabled: true # 开启feign对HttpClient的支持
    max-connections: 200 # 最大的连接数
    max-connections-per-route: 50 # 每个路径的最大连接数
```

#### 企业实践

- 在企业中使用feign其实更多的是将feign接口抽取出来，然后在本服务内将feign服务注入，之后直接调用该接口
- 要注意：要添加扫描包的范围@EnableFeignClients(clients = {UserClient.class})，否则会找不到对应的client包
- 也可以简单粗暴的使用继承的方式，例如在a服务中写好feign接口，然后直接在b服务把a注入就可以了但这样耦合度就太高了

### GateWay网关

#### 作用

- 身份验证，权限校验
- 用户请求路由到微服务，负载均衡
- 用户请求的限流

#### 配置

引入依赖：

```xml
<!--网关-->
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-gateway</artifactId>
</dependency>
<!--nacos服务发现依赖-->
<dependency>
    <groupId>com.alibaba.cloud</groupId>
    <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>
</dependency>
```

编写配置文件

创建application.yml文件，内容如下：

```yaml
server:
  port: 10010 # 网关端口
spring:
  application:
    name: gateway # 服务名称
  cloud:
    nacos:
      server-addr: localhost:8848 # nacos地址
    gateway:
      routes: # 网关路由配置
        - id: user-service # 路由id自定义的 但要唯一
          # uri: http://127.0.0.1:8081 # 路由地址，可以是具体的IP地址
          uri: lb://userservice # 路由地址lb是负载均衡 后面是服务名称
          predicates: # 断言
            - Path=/user/** # 代表以user开头的请求都发送到userservice服务
```

#### 路由工厂

一般就使用哦个Path这个

`org.springframework.cloud.gateway.handler.predicate.PathRoutePredicateFactory`类来处理

去读取用户定义的断言条件，并作出判断

| **名称**   | **说明**                       | **示例**                                                     |
| ---------- | ------------------------------ | ------------------------------------------------------------ |
| After      | 是某个时间点后的请求           | -  After=2037-01-20T17:42:47.789-07:00[America/Denver]       |
| Before     | 是某个时间点之前的请求         | -  Before=2031-04-13T15:14:47.433+08:00[Asia/Shanghai]       |
| Between    | 是某两个时间点之前的请求       | -  Between=2037-01-20T17:42:47.789-07:00[America/Denver],  2037-01-21T17:42:47.789-07:00[America/Denver] |
| Cookie     | 请求必须包含某些cookie         | - Cookie=chocolate, ch.p                                     |
| Header     | 请求必须包含某些header         | - Header=X-Request-Id, \d+                                   |
| Host       | 请求必须是访问某个host（域名） | -  Host=**.somehost.org,**.anotherhost.org                   |
| Method     | 请求方式必须是指定方式         | - Method=GET,POST                                            |
| Path       | 请求路径必须符合指定规则       | - Path=/red/{segment},/blue/**                               |
| Query      | 请求参数必须包含指定参数       | - Query=name, Jack或者-  Query=name                          |
| RemoteAddr | 请求者的ip必须是指定范围       | - RemoteAddr=192.168.1.1/24                                  |
| Weight     | 权重处理                       |                                                              |

####  过滤器

- 路由过滤器和默认过滤器


```yaml
spring:
  cloud:
    gateway:
      routes:
      - id: user-service 
        uri: lb://userservice 
        predicates: 
        - Path=/user/** 
        filters: # 过滤器
        - AddRequestHeader=Truth, Itcast is freaking awesome! # 路由过滤器添加请求头
      default-filters: # 默认过滤项
      - AddRequestHeader=Truth, Itcast is freaking awesome!   
```

路由过滤器只对当前服务生效；默认过滤器对全局生效。

- GatewayFilter通过配置定义，处理逻辑是固定的；而GlobalFilter的逻辑需要自己写代码实现

```java
@Order(-1)//执行顺序
@Component
public class AuthorizeFilter implements GlobalFilter {
    @Override
    public Mono<Void> filter(ServerWebExchange exchange, GatewayFilterChain chain) {
        // 1.获取请求参数
        MultiValueMap<String, String> params = exchange.getRequest().getQueryParams();
        // 2.获取authorization参数
        String auth = params.getFirst("authorization");
        // 3.校验
        if ("admin".equals(auth)) {
            // 放行
            return chain.filter(exchange);
        }
        // 4.拦截
        // 4.1.禁止访问，设置状态码
        exchange.getResponse().setStatusCode(HttpStatus.FORBIDDEN);
        // 4.2.结束处理
        return exchange.getResponse().setComplete();
    }
}
```

- 执行顺序，根据order来，自定义的自己定order，路由和默认的按声明顺序从1开始；当order值相同时 默认>路由>自定义

#### 跨域问题

在gateway服务的application.yml文件中，添加下面的配置：

```yaml
spring:
  cloud:
    gateway:
      # 。。。
      globalcors: # 全局的跨域处理
        add-to-simple-url-handler-mapping: true # 解决options请求被拦截问题
        corsConfigurations:
          '[/**]':
            allowedOrigins: # 允许哪些网站的跨域请求 
              - "http://localhost:8090"
            allowedMethods: # 允许的跨域ajax的请求方式
              - "GET"
              - "POST"
              - "DELETE"
              - "PUT"
              - "OPTIONS"
            allowedHeaders: "*" # 允许在请求中携带的头信息
            allowCredentials: true # 是否允许携带cookie
            maxAge: 360000 # 这次跨域检测的有效期
```

## 异步通信

#### 同步通信

- 时效性强，可以立即得到结果
- 耦合性高，吞吐能力不够，有额外的资源浪费，级联失败

#### 异步通信

- 优点：吞吐量提升；故障隔离（不存在级联失败）；耦合度低，流量削峰
- 缺点：架构复杂；依赖于broker的稳定与性能



几种常见MQ的对比：

|            | **RabbitMQ**            | **ActiveMQ**                   | **RocketMQ** | **Kafka**  |
| ---------- | ----------------------- | ------------------------------ | ------------ | ---------- |
| 公司/社区  | Rabbit                  | Apache                         | 阿里         | Apache     |
| 开发语言   | Erlang                  | Java                           | Java         | Scala&Java |
| 协议支持   | AMQP，XMPP，SMTP，STOMP | OpenWire,STOMP，REST,XMPP,AMQP | 自定义协议   | 自定义协议 |
| 可用性     | 高                      | 一般                           | 高           | 高         |
| 单机吞吐量 | 一般                    | 差                             | 高           | 非常高     |
| 消息延迟   | 微秒级                  | 毫秒级                         | 毫秒级       | 毫秒以内   |
| 消息可靠性 | 高                      | 一般                           | 高           | 一般       |

#### RabbitMQ

主要角色

- publisher：生产者
- consumer：消费者
- exchanger：交换机，负责消息路由
- queue：队列，存储消息
- virtualHost：虚拟主机，隔离不同租户的exchange、queue、消息的隔离

```java
public class PublisherTest {
    @Test
    public void testSendMessage() throws IOException, TimeoutException {
        // 1.建立连接
        ConnectionFactory factory = new ConnectionFactory();
        // 1.1.设置连接参数，分别是：主机名、端口号、vhost、用户名、密码
        factory.setHost("192.168.150.101");
        factory.setPort(5672);
        factory.setVirtualHost("/");
        factory.setUsername("itcast");
        factory.setPassword("123321");
        // 1.2.建立连接
        Connection connection = factory.newConnection();

        // 2.创建通道Channel
        Channel channel = connection.createChannel();

        // 3.创建队列
        String queueName = "simple.queue";
        channel.queueDeclare(queueName, false, false, false, null);

        // 4.发送消息
        String message = "hello, rabbitmq!";
        channel.basicPublish("", queueName, null, message.getBytes());
        System.out.println("发送消息成功：【" + message + "】");

        // 5.关闭通道和连接
        channel.close();
        connection.close();

    }
}
```

rabbitMQ实现方法，很繁琐，使用SpringAMQP要好很多

#### SpringAMQP

- SpringAMQP是基于RabbitMQ封装的一套模板，并且还利用SpringBoot对其实现了自动装配，使用起来非常方便。

- SpringAmqp的官方地址：https://spring.io/projects/spring-amqp
- 可以在Java中自动声明队列和交换机及其绑定关系
- 基于@RabbitListener注解做的消费者接受消息
- 封装了RabbitTemplate工具，用于发送消息 

##### 使用步骤

引入依赖

```xml
<!--AMQP依赖，包含RabbitMQ-->
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-amqp</artifactId>
</dependency>
```

配置MQ地址，在publisher/consumer服务的application.yml中添加配置：

```yaml
spring:
  rabbitmq:
    host: 192.168.150.101 # 主机名
    port: 5672 # 端口，15672是图形化页面
    virtual-host: / # 虚拟主机
    username: itcast # 用户名
    password: 123321 # 密码
```

发送消息代码

```java
    @Autowired
    private RabbitTemplate rabbitTemplate;
	@Test
    public void testSimpleQueue() {
        // 队列名称
        String queueName = "yang.queue";
        // 消息
        String message = "hello, spring amqp!";
        // 发送消息
        rabbitTemplate.convertAndSend(queueName, message);
    }
```

监听消息代码

```java
 @RabbitListener(queues = "yang.queue")
    public void listenSimpleQueueMessage(String msg) throws InterruptedException {
        System.out.println("spring 消费者接收到消息：【" + msg + "】");
    }
```

当有多个消费者时，消息都是被平均消费的，不会根据性能去匹配消息量;

可以在配置文件中修改

```yaml
spring:
  rabbitmq:
    listener:
      simple:
        prefetch: 1 # 每次只能获取一条消息，处理完成才能获取下一个消息
```

##### exchange交换机

- **Exchange（交换机）只负责转发消息，不具备存储消息的能力**，因此如果没有任何队列与Exchange绑定，或者没有符合路由规则的队列，那么消息会丢失！

  - Fanout：广播，将消息交给所有绑定到交换机的队列
  - Direct：定向，把消息交给符合指定routing key 的队列
  - Topic：通配符，把消息交给符合routing pattern（路由模式） 的队列

- Fanout广播交换机

  - 在这种模式下，提供者会将消息发送给交换机，交换机会把消息发送给每一个消费者

  - ```java
    @Configuration
    public class FanoutConfig {
        //声明交换机
        @Bean
        public FanoutExchange fanoutExchange () {
            return new FanoutExchange("fanout.exchange");
        }
        //声明队列
        @Bean
        public Queue fanoutQueue () {
            return new Queue("queue");
        }
        //队列绑定
        @Bean
        public Binding fanoutBind(FanoutExchange fanoutExchange, Queue queue) {
            return BindingBuilder.bind(queue).to(fanoutExchange);
        }
    }
    ```

  - ```java
    //这种情况下，消息要发送到交换机，因此要指定交换机的名称
    //消息的接收和消费还是一样的
    @Test
    public void testFanoutExchange() {
        // 交换机名称
        String exchangeName = "fanout.exchange";
        // 消息 
        String message = "hello, everyone!";
        rabbitTemplate.convertAndSend(exchangeName, "", message);
    }
    ```

- Direct定向交换机

  - 在fanout模式中，所有的消费者都会收到消息，但其实有些场景我们希望不同的消息被不同的消费者拿到，所以需要Direct类型的交换机，

  - 因此消息队列与交换机的绑定，不能是任意绑定了，而是要指定一个`RoutingKey`（路由key）；而这导致需要写很多Bean，因此可以直接在RabbitListener中绑定路由和队列

    ```java
     @RabbitListener(bindings = @QueueBinding(
                key = {"blue"},//数组，可以是多个
                value = @Queue(name = "direct.queue"),
                exchange = @Exchange(name = "direct.exchange",type = ExchangeTypes.DIRECT)
        ))
        public void test(String meg) {
    //只消费direct.exchange交换机上key是blue的direct.queue队列的消息
        }
    
       // 发送消息的时候也要指定好key；例如下面这个发送就不对被上面的消费者消费
        rabbitTemplate.convertAndSend(exchangeName, "red", message);
    ```

  - 当两个消费者的key一样时，就类似于上面的fanout交换机了

- Topic通配符交换机

  - 这个和上面的类似，只是在绑定key时不需要一个一个写了，可以用通配符占位
  - #代表0个或多个词；*代表一个词

##### 消息转换器

- spring在发送和接受消息的时候都会把消息序列化，而spring使用的是jdk序列化，可读性很差而且内存很大

- 所以需要使用json作为转换对象

- ```xml
  <dependency>
      <groupId>com.fasterxml.jackson.dataformat</groupId>
      <artifactId>jackson-dataformat-xml</artifactId>
      <version>2.9.10</version>
  </dependency>
  ```

  引入依赖后，在启动类加一个bean，把mq本身的序列化换掉就行

- ```java
  @Bean
  public MessageConverter jsonMessageConverter(){
      return new Jackson2JsonMessageConverter();
  }
  ```

  

## 分布式搜索

#### 基本概念

- es是一个开源的搜索引擎，可以在海量数据中查询到想要的结果；
- ELK技术栈：elasticsearch结合kibana、Logstash、Beats，也就是elastic stack（ELK）。被广泛应用在日志数据分析、实时监控等领域
- es的底层是由Lucene(开源搜索引擎类库，提供了搜索核心API)

##### 倒序索引

- mysql中的索引是正序索引，而es是反的，所以就叫倒序索引了
- 倒序索引的两个主要概念是：文档和词条
  - 用来搜索的数据就是文档，例如数据库中的一行数据就是一个文档
  - 对用户搜索的数据或者文档利用分词器分得到具有含义的词语就是词条
- 创建倒序索引
  - 将每一个文档的数据利用算法分词，得到一个个词条
  - 创建表，表中包含词条，词条所在的文档id，位置等信息
  - 因为词条是唯一的(如果有其他文档的词条，就在该词条下添加文档id保证唯一)，所以给词条加唯一索引
- 优点是根据词条搜索时速度快；缺点是只能给词条加索引，无法给字段加索引或者加判断

mysql与elasticsearch的对比：

| **MySQL** | **Elasticsearch** | **说明**                                                     |
| --------- | ----------------- | ------------------------------------------------------------ |
| Table     | Index             | 索引(index)，就是文档的集合，类似数据库的表(table)           |
| Row       | Document          | 文档（Document），就是一条条的数据，类似数据库中的行（Row），文档都是JSON格式 |
| Column    | Field             | 字段（Field），就是JSON文档中的字段，类似数据库中的列（Column） |
| Schema    | Mapping           | Mapping（映射）是索引中文档的约束，例如字段类型约束。类似数据库的表结构varchar类型等等 |
| SQL       | DSL               | DSL是elasticsearch提供的JSON风格的请求语句，用来操作elasticsearch，实现CRUD |

#### es安装

1. 因为我们还需要部署kibana容器，因此需要让es和kibana容器互联。这里先创建一个网络：

   ```sh
   docker network create es-net
   ```

2. 将es，kibana压缩包上传到虚拟机中，然后运行命令加载即可：

   ```sh
   # 导入数据
   docker load -i es.tar
   ```

3. 运行docker命令，部署单点es：

   ```sh
   docker run -d \
   	--name es \
       -e "ES_JAVA_OPTS=-Xms512m -Xmx512m" \
       -e "discovery.type=single-node" \
       -v es-data:/usr/share/elasticsearch/data \
       -v es-plugins:/usr/share/elasticsearch/plugins \
       --privileged \
       --network es-net \
       -p 9200:9200 \
       -p 9300:9300 \
   elasticsearch:7.12.1
   ```

   命令解释：

   - `-e "cluster.name=es-docker-cluster"`：设置集群名称
   - `-e "http.host=0.0.0.0"`：监听的地址，可以外网访问
   - `-e "ES_JAVA_OPTS=-Xms512m -Xmx512m"`：内存大小
   - `-e "discovery.type=single-node"`：非集群模式
   - `-v es-data:/usr/share/elasticsearch/data`：挂载逻辑卷，绑定es的数据目录
   - `-v es-logs:/usr/share/elasticsearch/logs`：挂载逻辑卷，绑定es的日志目录
   - `-v es-plugins:/usr/share/elasticsearch/plugins`：挂载逻辑卷，绑定es的插件目录
   - `--privileged`：授予逻辑卷访问权
   - `--network es-net` ：加入一个名为es-net的网络中
   - `-p 9200:9200`：端口映射配置

   在浏览器中输入：http://虚拟机地址:9200 即可看到elasticsearch的响应结果：

4. 运行docker命令，部署kibana(图形化界面的操作)

   ```sh
   docker run -d \
   --name kibana \
   -e ELASTICSEARCH_HOSTS=http://es:9200 \
   --network=es-net \
   -p 5601:5601  \
   kibana:7.12.1
   ```

   - `--network es-net` ：加入一个名为es-net的网络中，与elasticsearch在同一个网络中
   - `-e ELASTICSEARCH_HOSTS=http://es:9200"`：设置elasticsearch的地址，因为kibana已经与elasticsearch在一个网络，因此可以用容器名直接访问elasticsearch
   - `-p 5601:5601`：端口映射配置

5. 安装ik插件(分词器)

   1. 安装插件需要知道elasticsearch的plugins目录位置，而我们用了数据卷挂载，因此需要查看elasticsearch的数据卷目录，通过下面命令查看:

   ```sh
   docker volume inspect es-plugins
   ```

   显示结果：

   ```json
   [
       {
           "CreatedAt": "2022-05-06T10:06:34+08:00",
           "Driver": "local",
           "Labels": null,
           "Mountpoint": "/var/lib/docker/volumes/es-plugins/_data",
           "Name": "es-plugins",
           "Options": null,
           "Scope": "local"
       }
   ]
   ```

   说明plugins目录被挂载到了：`/var/lib/docker/volumes/es-plugins/_data `这个目录中。

   ik分词器解压缩，重命名为ik；之后重启容器即可 docker restart es

   IK分词器包含两种模式：

   * `ik_smart`：最少切分（有三个字的词就不会再切分了）
   * `ik_max_word`：最细切分

6. 拓展词典

   - 打开IK分词器config目录在IKAnalyzer.cfg.xml配置文件内容添加：

     ```xml
     <?xml version="1.0" encoding="UTF-8"?>
     <!DOCTYPE properties SYSTEM "http://java.sun.com/dtd/properties.dtd">
     <properties>
             <comment>IK Analyzer 扩展配置</comment>
             <!--用户可以在这里配置自己的扩展字典 *** 添加扩展词典-->
             <entry key="ext_dict">ext.dic</entry>
          <!--用户可以在这里配置自己的扩展停止词字典  *** 添加停用词词典-->
             <entry key="ext_stopwords">stopword.dic</entry>
     </properties>
     ```

     3）新建一个 ext.dic，stopword.dic；可以参考config目录下复制一个配置文件进行修改

     4）重启elasticsearch 

     ```sh
     # 重启服务
     docker restart es
     docker restart kibana
     ```

#### 索引库操作

##### mapping映射

- 索引库就类似于数据库中的表，而mapping映射就对应了索引库中的表结构

- mapping映射是对索引库中文档的约束
  - type：字段数据类型字符串：
    - text（可分词的文本）、keyword（精确值，例如：品牌、国家、ip地址）
    - 数值：long、integer、short、byte、double、float、
    - 布尔：boolean日期：
    - date对象：object
    - 地理坐标：geo_point：里面包含精度、纬度
  - index：是否创建索引，默认为true
  - analyzer：使用哪种分词器
  - properties：该字段的子字段

- 例如下面的json文档：


```json
{
    "age": 21,
    "weight": 52.1,
    "isMarried": false,
    "info": "他日若遂凌云志",
    "email": "zy@itcast.cn",
    "score": [99.1, 99.5, 98.9],
    "name": {
        "firstName": "云",
        "lastName": "赵"
    }
}
```

对应的每个字段映射（mapping）：

- age：类型为 integer；参与搜索，因此需要index为true；无需分词器
- weight：类型为float；参与搜索，因此需要index为true；无需分词器
- isMarried：类型为boolean；参与搜索，因此需要index为true；无需分词器
- info：类型为字符串，需要分词，因此是text；参与搜索，因此需要index为true；分词器可以用ik_smart
- email：类型为字符串，但是不需要分词，因此是keyword；不参与搜索，因此需要index为false；无需分词器
- score：虽然是数组，但是我们只看元素的类型，类型为float；参与搜索，因此需要index为true；无需分词器
- name：类型为object，需要定义多个子属性
  - name.firstName；类型为字符串，但是不需要分词，因此是keyword；参与搜索，因此需要index为true；无需分词器
  - name.lastName；类型为字符串，但是不需要分词，因此是keyword；参与搜索，因此需要index为true；无需分词器

##### 索引库的CRUD

- 新增索引库：put /索引库名称

- ```json
  PUT /yang
  {
    "mappings": {
      "properties": {
        "info":{
          "type": "text",
          "analyzer": "ik_smart",
          "copy_to": "all"
        },
        "email":{
          "type": "keyword",
          "index": "false"
        },
        "name":{
          "properties": {
            "firstName":{
              "type": "keyword",
              "copy_to": "all"  
            }
          }
        },
        "all":{
            # all是将其他的多个字段利用copy_to合并，提供给用户搜索
          "type": "text",
          "analyzer": "ik_max_word"
        }
      }
    }
  }
  ```

- 查询索引库：GET /索引库名

- 删除索引库：DELETE /索引库名

- 修改索引库

  - 索引库是不支持已有字段修改的，但是可以新增字段

  - ```json
    PUT /索引库名/_mapping
    {
      "properties": {
        "新字段名":{
          "type": "integer"
        }
      }
    }
    ```

##### 文档的CRUD

- 新增文档

- ```json
  POST /索引库名/_doc/文档id
  {
      "字段1": "值1",
      "字段2": "值2",
      "字段3": {
          "子属性1": "值3",
          "子属性2": "值4"
      },
      // ...
  }
  ```

- 查询文档：GET /{索引库名称}/_doc/{id}

- 删除文档：DELETE /{索引库名}/_doc/id值

- 修改文档

- ```json
  # 全量修改，会把旧文档全部删掉然后插入新的
  PUT /{索引库名}/_doc/文档id
  {
      "字段1": "值1",
      "字段2": "值2",
      // ... 略
  }
  
  ```

- ```json
  # 局部修改，只会修改指定的字段
  POST /{索引库名}/_update/文档id
  {
  "doc":{
      "字段1": "值1",
      "字段2": "值2",
      // ... 略
  }
  }
  ```

- 但是，不管是全量还是局部修改，如果你把字段名称给写错了，比如name写成了name4那默认会给你新增一个字段叫name4，当然区别是全量的就剩下name4了而局部是多加了一个name4；因此可以关闭动态映射功能或设置为严格模式（"strict"）这样写错了就会报错而不是新增

- ```json
  PUT /my_index
  {
    "mappings": {
      "properties": {
        "field1": { "type": "text" }
      }
    },
    "settings": {
      "index.mapping.dynamic": false
    }
  }
  # 或者
  PUT /my_index
  {
    "mappings": {
      "dynamic": "strict",
      "properties": {
        "field1": { "type": "text" },
        "field2": { "type": "integer" }
      }
    }
  }
  ```

#### RestAPI

- 通过Java操作es的api---->Java High Level Rest Client

- 1）引入es的RestHighLevelClient依赖：

- ```xml
  <dependency>
      <groupId>org.elasticsearch.client</groupId>
      <artifactId>elasticsearch-rest-high-level-client</artifactId>
  </dependency>
  ```


- 2）因为SpringBoot默认的ES版本是7.6.2，所以我们需要覆盖默认的ES版本：

- ```xml
  <properties>
      <java.version>1.8</java.version>
      <elasticsearch.version>7.12.1</elasticsearch.version>
  </properties>
  ```


##### 操作索引库

1. 建立连接

   ```java
   RestHighLevelClient client = new RestHighLevelClient(RestClient.builder(
           HttpHost.create("http://192.168.150.101:9200")
   ));
   ```

2. 新增索引库

   ```java
   CreateIndexRequest request = new CreateIndexRequest("hotel");//创建request
   request.source("DSL语句",XContentType.JSON);//放入DSL语句从mappings开始就行
   client.indices().create(request,RequestOptions.DEFAULT);//发送索引库请求
   ```

3. 查询索引库

   ```java
   GetIndexRequest request = new GetIndexRequest("xx");//创建request
   boolean exists = client.indices().exists(request, RequestOptions.DEFAULT);//发送请求
   System.out.println(exists ? "我在" : "我没了");//会告诉你索引库还在不在
   ```

4. 删除索引库

   ```java
   DeleteIndexRequest request = new DeleteIndexRequest("hotel");//建立请求
   client.indices().delete(request,RequestOptions.DEFAULT);//发送
   ```

##### 操作文档

1. 同上，创建RestHighLevelClient连接

2. 创建文档

   ```java
   //创建一个实体类，根据索引库的类型
   //查出数据===》转化成上面的实体类====》转换成json格式
   		 // 1.准备Request
   IndexRequest request = new IndexRequest("hotel").id(hotelDoc.getId().toString());
           // 2.准备请求参数DSL，其实就是文档的JSON字符串
   request.source(json, XContentType.JSON);
           // 3.发送请求
   client.index(request, RequestOptions.DEFAULT);
   ```

3. 查询文档

   ```java
   GetRequest request = new GetRequest("hotel", "111");
   GetResponse response = client.get(request, RequestOptions.DEFAULT);
   String source = response.getSourceAsString();
   HotelDoc hotelDoc = JSON.parseObject(source, HotelDoc.class);
   ```

4. 删除文档

   ```java
   // 1.准备Request      // DELETE /hotel/_doc/{id}
   DeleteRequest request = new DeleteRequest("hotel", "61083");
   // 2.发送请求
   client.delete(request, RequestOptions.DEFAULT);
   ```

5. 修改文档

   ```
    // 1.准备Request
   UpdateRequest request = new UpdateRequest("hotel", "61083");
           // 2.准备参数
   	request.doc(
                   "price", "870",
                   "name","张飞"
                   //两两一组，逗号分隔
           );
           // 3.发送请求
    client.update(request, RequestOptions.DEFAULT);
   ```

6. 批量操作

   ```java
   / 1.准备Request
    BulkRequest request = new BulkRequest();
           // 2.准备参数
           for (Hotel hotel : list) {
               // 2.1.转为HotelDoc
               HotelDoc hotelDoc = new HotelDoc(hotel);
               // 2.2.转json
               String json = JSON.toJSONString(hotelDoc);
               // 2.3.添加请求
   request.add(new IndexRequest("hotel").id(hotel.getId().toString()).source(json, XContentType.JSON));
           }
           // 3.发送请求
   client.bulk(request, RequestOptions.DEFAULT);
   ```



## Sentinel

### 微服务雪崩

- 在微服务调用链路中其中一个服务故障而导致整个链路的微服务全部不可用就是微服务的雪崩
- 如何解决
  - 超时处理：设定超时时间，如果请求超过一定的时间没有响应就返回错误信息，不再无休止等待
  - 舱壁模式：因为超时只能缓解，不能彻底解决，舱壁模式限定每个业务的线程数，避免耗尽资源因此也叫线程隔离
  - 熔断降级：舱壁会浪费资源-已经挂了还去访问，熔断模式由断路器统计业务的异常比例，达到设定的阈值后会熔断该业务，拦截对该业务的一切请求
  - 流量控制：限制访问的QPS(每秒钟访问次数)，避免服务因流量突增而故障
- sentinel主要就是使用舱壁 熔断降级 和流量控制来避免
  - 引入jar包，配置好yml文件后，可以在sentinel的页面进行  流控，降级，热点，授权的操作
  - sentinel只对Controller中的方法资源标识，如果要监控service中的方法就要添加注解@SentinelResource，并且将yml文件中的web-context-unify设置为false，即关闭context整合否则所有的controller都被认为是一个根链路无法做链路控制
  - 流控：只需要配置QPS阈值即可，也就是每秒的访问上超过上限的线程都会拒绝报错429
    - 流控有三种模式（直接[默认]，关联，链路）；直接模式是默认的，当前线程达到阈值就会阻塞；关联模式是对两个不同优先级的线程进行流控，在低优先级的服务中做流控，当高优先级的服务超过阈值时就会对低优先级的服务进行阻塞；链路模式是针对其中一个请求来源做限制，即a,b两个链路来请求只针对某一个做限制
    - 流控效果（快速失败，Warm Up，排队等待）默认是快速失败，一旦达到阈值会马上报错抛出异常；预热模式是将阈值逐渐放大的，为了防止服务冷启动时请求过多导致服务崩溃，初始阈值=最大阈值/3，在设定的预热时间内提高到最大阈值；排队等待，将进入请求的流量放入队列中，按设置好的时间间隔放行达到流量整形的效果，适用于流量波动的请求
  - 热点：热点参数限流只针对请求中某个参数的，将同一参数的请求数归为一类，高级选项中可以针对特殊的参数进行不同阈值的设定来灵活应用
    - 参数类型只能时基本类型和string类型
    - 对mvc默认的资源是无效的，如果要使用要加@SetinelResource注解才可以
  - 